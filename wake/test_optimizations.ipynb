{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Loaded model\n",
      "Model: \"model_GRU_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_4 (GRU)                 (None, 20)                2100      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,121\n",
      "Trainable params: 2,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\noah\\AppData\\Local\\Temp\\tmptyokschl\\assets\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Convert with no optimization\n",
    "\"\"\"\n",
    "\n",
    "KERAS_MODEL = r'.\\checkpoints\\model_GRU_20'\n",
    "\n",
    "import convert_model\n",
    "# Reload\n",
    "import importlib\n",
    "importlib.reload(convert_model)\n",
    "\n",
    "\n",
    "convert_model.convert_model(KERAS_MODEL, optimizations=None, save_path='model_no_optimizations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of data positive: 19.71%%\n",
      "train_x size:  57.525634765625 MB\n",
      "20000\n",
      "Percent of data positive: 0.03%%\n",
      "val_x size:  102.68038177490234 MB\n",
      "35699\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from parameters import FileParams as fp\n",
    "\n",
    "# Load training data\n",
    "count_training = 20000\n",
    "train_x = np.load(os.path.join(fp.data_dir, 'train_x.npy'))[:count_training]\n",
    "train_y = np.load(os.path.join(fp.data_dir, 'train_y.npy'))[:count_training]\n",
    "print(f'Percent of data positive: {np.mean(train_y) * 100:.2f}%%')\n",
    "print('train_x size: ', train_x.nbytes / 1024 / 1024, 'MB')\n",
    "print(len(train_x))\n",
    "\n",
    "# Load validation data\n",
    "val_x = np.load(os.path.join(fp.data_dir, 'val_x.npy'))\n",
    "val_y = np.load(os.path.join(fp.data_dir, 'val_y.npy'))\n",
    "print(f'Percent of data positive: {np.mean(val_y) * 100:.2f}%%')\n",
    "print('val_x size: ', val_x.nbytes / 1024 / 1024, 'MB')\n",
    "print(len(val_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_GRU_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_4 (GRU)                 (None, 20)                2100      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,121\n",
      "Trainable params: 2,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Keras file size:  0.00390625 MB\n"
     ]
    }
   ],
   "source": [
    "# Eval baseline model\n",
    "import keras\n",
    "\n",
    "keras_model: keras.Model = keras.models.load_model(KERAS_MODEL)\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 3s 5ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "Train loss: 0.0013221293920651078, Train accuracy: 0.9994999766349792\n"
     ]
    }
   ],
   "source": [
    "# Eval on train data\n",
    "loss, baseline_train_accuracy = keras_model.evaluate(train_x, train_y)\n",
    "print(f'Train loss: {loss}, Train accuracy: {baseline_train_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1116/1116 [==============================] - 6s 5ms/step - loss: 3.4206e-04 - accuracy: 0.9999\n",
      "Val loss: 0.00034205790143460035, Val accuracy: 0.9998879432678223\n"
     ]
    }
   ],
   "source": [
    "# Eval on validation data\n",
    "loss, baseline_val_accuracy = keras_model.evaluate(val_x, val_y)\n",
    "print(f'Val loss: {loss}, Val accuracy: {baseline_val_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "from model.modelwrapper import ModelWrapper, get_model_wrapper\n",
    "\n",
    "def predict_all(model_wrapper: ModelWrapper, data):\n",
    "    output_array = []\n",
    "    for i in tqdm(range(len(data))):\n",
    "        input_data = data[i]\n",
    "        output_piece = model_wrapper.predict(input_data)\n",
    "        output_array.append(output_piece)\n",
    "    return np.array(output_array).flatten()\n",
    "\n",
    "def get_accuracy(model_wrapper: ModelWrapper, x, y):\n",
    "    predictions = predict_all(model_wrapper, x)\n",
    "    predictions = np.array(predictions).flatten()\n",
    "    predictions = np.round(predictions)\n",
    "    return np.mean(predictions == y)\n",
    "\n",
    "def load_and_get_accuracy(model_path):\n",
    "    model_wrapper = get_model_wrapper(model_path)  # Load model\n",
    "    train_accuracy = get_accuracy(model_wrapper, train_x, train_y)  # Get train accuracy\n",
    "    val_accuracy = get_accuracy(model_wrapper, val_x, val_y)  # Get val accuracy\n",
    "    return train_accuracy, val_accuracy, model_wrapper  # Return train acc, val acc, and model wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os_name = nt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:05<00:00, 3762.45it/s]\n",
      "100%|██████████| 35699/35699 [00:09<00:00, 3720.51it/s]\n"
     ]
    }
   ],
   "source": [
    "no_optimizations_train_accuracy, no_optimizations_val_accuracy, no_optimizations_model = load_and_get_accuracy(\"model_no_optimizations.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 19.25 KB\n",
      "Memory size: 48 Bytes\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "file_size = os.path.getsize(\"model_no_optimizations.tflite\") / 1024\n",
    "print(f'File size: {file_size} KB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy diff: -2.3365020807020187e-08\n",
      "Val accuracy diff: -8.775652315939908e-09\n"
     ]
    }
   ],
   "source": [
    "train_diff = baseline_train_accuracy - no_optimizations_train_accuracy\n",
    "val_diff = baseline_val_accuracy - no_optimizations_val_accuracy\n",
    "print(f'Train accuracy diff: {train_diff}')\n",
    "print(f'Val accuracy diff: {val_diff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model\n",
      "Model: \"model_GRU_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_4 (GRU)                 (None, 20)                2100      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,121\n",
      "Trainable params: 2,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\noah\\AppData\\Local\\Temp\\tmp_hpoexh2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\noah\\AppData\\Local\\Temp\\tmp_hpoexh2\\assets\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Convert with default optimization\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "convert_model.convert_model(KERAS_MODEL, optimizations=[tf.lite.Optimize.DEFAULT], save_path='model_default_optimizations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os_name = nt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:05<00:00, 3433.78it/s]\n",
      "100%|██████████| 35699/35699 [00:10<00:00, 3431.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy diff: -2.3365020807020187e-08\n",
      "Val accuracy diff: -2.8020764783698304e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "default_train_acc, default_val_acc, default_optimizations_model = load_and_get_accuracy(\"model_default_optimizations.tflite\")\n",
    "print(f'Train accuracy diff: {baseline_train_accuracy - default_train_acc}')\n",
    "print(f'Val accuracy diff: {baseline_val_accuracy - default_val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 15.8828125 MB\n",
      "Memory size: 48 Bytes\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "file_size = os.path.getsize(\"model_default_optimizations.tflite\") / 1024\n",
    "print(f'File size: {file_size} MB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse517",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
