{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\noah\\\\repos\\\\BTLR\\\\wake\\\\data\\\\cv-corpus-15.0-delta-2023-09-08\\\\en\\\\clips\\\\common_voice_en_38024625.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.isfile(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from parameters import MycroftParams as ap\n",
    "\n",
    "y, sr = librosa.load(path, sr=ap.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "audio_data = np.squeeze(y)\n",
    "audio_data = audio_data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "mfcc = data.get_mfcc(audio_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82368\n",
      "101\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The first dimension of the MFCC is the number of individual frames (or windows)\n",
    "that make up the audio\n",
    "'''\n",
    "from parameters import MycroftParams as ap\n",
    "audio_length = len(audio_data)\n",
    "print(audio_length)\n",
    "window_size = ap.window_samples\n",
    "hop_size = ap.hop_samples\n",
    "\n",
    "number_frames = (audio_length - window_size) // hop_size + 1\n",
    "print(number_frames)\n",
    "print(len(mfcc))\n",
    "assert(number_frames == len(mfcc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The second dimension of the MFCC is always the coefficients, so the size will\n",
    "be the number of spectrogram coefficients.\n",
    "'''\n",
    "\n",
    "assert(mfcc.shape[1] == ap.n_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "import librosa\n",
    "y, sr = librosa.load(path, sr=None)\n",
    "# Convert to numpy\n",
    "import numpy as np\n",
    "audio_data = np.squeeze(y)\n",
    "audio_data = audio_data.astype(np.float32)\n",
    "# Convert to MFCC\n",
    "import data\n",
    "mfcc = data.get_mfcc(audio_data)  # shape (total_timesteps x n_mfcc)\n",
    "# Reshape to fit into model\n",
    "\n",
    "# make sure it is even multiple of size n_features\n",
    "remainder = len(mfcc) % ap.n_features\n",
    "\n",
    "if (remainder != 0):\n",
    "    # append zeros to beginning\n",
    "    count_zeros = ap.n_features - remainder\n",
    "    mfcc = np.concatenate([\n",
    "            np.zeros((count_zeros, mfcc.shape[1])),\n",
    "            mfcc\n",
    "        ])\n",
    "assert(len(mfcc) % ap.n_features == 0)\n",
    "\n",
    "sections = len(mfcc) // ap.n_features\n",
    "# input = np.split(mfcc, sections) # shape (n x n_features x n_mfcc)\n",
    "input = np.reshape(mfcc, (-1, ap.n_features, ap.n_mfcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232, 13)\n",
      "(8, 29, 13)\n",
      "[-12.26137182   2.76322785   0.65285486   2.76426243   0.18142609\n",
      "   1.91480465  -1.62400647   0.20190497  -1.58925434   1.37498852\n",
      "  -1.41271307   0.05049408   0.04853711]\n",
      "[-12.26137182   2.76322785   0.65285486   2.76426243   0.18142609\n",
      "   1.91480465  -1.62400647   0.20190497  -1.58925434   1.37498852\n",
      "  -1.41271307   0.05049408   0.04853711]\n"
     ]
    }
   ],
   "source": [
    "print(mfcc.shape)\n",
    "print(input.shape)\n",
    "index = 29\n",
    "print(mfcc[index])\n",
    "print(input[index // ap.n_features][index % ap.n_features])\n",
    "\n",
    "def same(index):\n",
    "    return np.array_equal(mfcc[index], input[index // ap.n_features][index % ap.n_features])\n",
    "\n",
    "for i in range(len(mfcc)):\n",
    "    if not same(i):\n",
    "        print('not same')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse517",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
