{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LOAD THE DATA\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "from parameters import FileParams as fp, DEFAULT_AUDIO_PARAMS as ap\n",
    "\n",
    "def load_data(dataset: str):\n",
    "    x = np.load(os.path.join(fp.data_dir, f'{dataset}_x.npy'))\n",
    "    y = np.load(os.path.join(fp.data_dir, f'{dataset}_y.npy'))\n",
    "    return x, y\n",
    "\n",
    "train_x, train_y = load_data('train')\n",
    "val_x, val_y = load_data('val')\n",
    "\n",
    "print(f'Percent of train data positive: {np.mean(train_y) * 100:.2f}%')\n",
    "print('train_x size: ', train_x.nbytes / 1024 / 1024, 'MB')\n",
    "print(f'Percent of val data positive: {np.mean(val_y) * 100:.2f}%')\n",
    "print('val_x size: ', val_x.nbytes / 1024 / 1024, 'MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "CREATE THE MODEL\n",
    "\n",
    "Model architecture copied from\n",
    "https://www.tensorflow.org/tutorials/audio/simple_audio\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "INPUT_SHAPE = (ap.n_features, ap.n_mfcc)\n",
    "MODEL_NAME = 'simple_cnn'\n",
    "\n",
    "# Instantiate the `tf.keras.layers.Normalization` layer.\n",
    "norm_layer = layers.Normalization()\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=INPUT_SHAPE),\n",
    "    norm_layer,\n",
    "    layers.Conv1D(32, 3, activation='relu'),\n",
    "    layers.Conv1D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling1D(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "], name=MODEL_NAME)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=binary_crossentropy,\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SET UP FOR TRAINING\n",
    "\"\"\"\n",
    "\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 4\n",
    "\n",
    "checkpoint_dir = f'./checkpoints/{MODEL_NAME}'\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_dir,\n",
    "    save_weights_only=False,  # Save the whole model\n",
    "    monitor='val_accuracy',\n",
    "    mode='auto',\n",
    "    save_best_only=True)\n",
    "\n",
    "log_dir = os.path.join(fp.log_dir, MODEL_NAME)\n",
    "callbacks = [TensorBoard(log_dir), model_checkpoint_callback]\n",
    "# Print out info about the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TRAIN THE MODEL\n",
    "\"\"\"\n",
    "model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(val_x, val_y),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluate on the validation set\n",
    "\"\"\"\n",
    "\n",
    "loss, accuracy = model.evaluate(val_x, val_y)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy*100:.5f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "USE THE MODEL TO MAKE PREDICTIONS\n",
    "\"\"\"\n",
    "\n",
    "predictions = model.predict(train_x[:10]).flatten()\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    print(f'Predicted: {predictions[i]:<.4f}, Actual: {train_y[i]}, {\"Correct!\" if round(predictions[i]) == train_y[i] else \"Incorrect\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TEST SMALLER MODEL\n",
    "\"\"\"\n",
    "\n",
    "SMALLER_NAME = 'smaller_cnn'\n",
    "\n",
    "# Same except half as many filters in the Conv1D layers\n",
    "norm_layer = layers.Normalization()\n",
    "smaller_model = models.Sequential([\n",
    "    layers.Input(shape=INPUT_SHAPE),\n",
    "    norm_layer,\n",
    "    layers.Conv1D(16, 3, activation='relu'),\n",
    "    layers.Conv1D(32, 3, activation='relu'),\n",
    "    layers.MaxPooling1D(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "], name=SMALLER_NAME)\n",
    "\n",
    "smaller_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "smaller_checkpoint_dir = f'./checkpoints/{SMALLER_NAME}'\n",
    "smaller_model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=smaller_checkpoint_dir,\n",
    "    save_weights_only=False,  # Save the whole model\n",
    "    monitor='val_accuracy',\n",
    "    mode='auto',\n",
    "    save_best_only=True)\n",
    "smaller_callbacks = [\n",
    "    TensorBoard(os.path.join(fp.log_dir, SMALLER_NAME)),\n",
    "    model_checkpoint_callback\n",
    "]\n",
    "smaller_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TRAIN THE SMALLER MODEL\n",
    "\"\"\"\n",
    "smaller_model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(val_x, val_y),\n",
    "    callbacks=smaller_callbacks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse517",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
